{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pickle\n",
    "from mmdetection.mmdet.apis import init_detector, inference_detector, show_result\n",
    "from tqdm import tqdm_notebook\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "prediction_file_path = 'preds.txt'\n",
    "ground_truth_file_path = 'ground-truth.txt'\n",
    "# anns = pickle.load(open('../../data/t3-data/splits/all/test.pkl', 'rb'))\n",
    "anns = pickle.load(open('../../data/t3-data/only_yaya_test_frames.pkl', 'rb'))\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone/epoch_1.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_mix/epoch_4.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone_pretrained/epoch_14.pth'\n",
    "\n",
    "# config_file = '../../src/configs/libra_rcnn/libra_retinanet_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/libra_retinanet_r50_fpn_1x/epoch_2.pth'\n",
    "\n",
    "config_file = '../configs/guided_anchoring/ga_retinanet_x101_32x4d_fpn_1x.py'\n",
    "checkpoint_file = '../../models/work_dirs/ga_retinanet_x101_32x4d_fpn_1x/latest.pth'\n",
    "\n",
    "\n",
    "# config_file = '../mmdetection/configs/retinanet_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/retinanet_r50_fpn_1x_visdrone/epoch_2.pth'\n",
    "\n",
    "# config_file = '../../src/configs/cascade_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../../models/work_dirs/cascade_rcnn_r50_fpn_1x-all/latest.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r101_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r101_fpn_1x/epoch_15.pth'\n",
    "\n",
    "# config_file = '../../models/google-cloud-models/cascade-t3-vis/config.py'\n",
    "# checkpoint_file = '../../models/google-cloud-models/cascade-t3-vis/epoch_1.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "model = init_detector(\n",
    "    config_file, \n",
    "#     batch_size=True,\n",
    "    checkpoint=checkpoint_file, \n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "\n",
    "img_list = ['../../data/t3-data/' + ann['filename'] for ann in anns]\n",
    "\n",
    "# img_list = [f for f in glob('../../data/ktr-test/test/B23072019_V1_K1/**.jpg')]\n",
    "# img_list = ['../../data/ktr-test/test/B23072019_V1_K1/frame3500.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "for imgs_sub in tqdm(range(0, len(img_list), batch_size)):\n",
    "    inference_detector(model, img_list[imgs_sub: imgs_sub+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "img_obj = pickle.load(open('img_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': [tensor([[[[-1.6042, -1.7069, -1.8097,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7069, -1.7583, -1.7754,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7754, -1.7925, -1.7754,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[-1.3704, -1.5105, -1.6331,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.4755, -1.5630, -1.5980,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.5455, -1.6155, -1.5980,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[-1.1073, -1.2467, -1.3513,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.1944, -1.2816, -1.3339,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.2641, -1.3339, -1.3339,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         device='cuda:0')],\n",
       " 'img_meta': [[{'ori_shape': (900, 1920, 3),\n",
       "    'img_shape': (625, 1333, 3),\n",
       "    'pad_shape': (640, 1344, 3),\n",
       "    'scale_factor': 0.6942708333333333,\n",
       "    'flip': False}]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(0, 5), dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(return_loss=False, rescale=True, **img_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for res in tqdm_notebook(inference_detector(model, img_list), total=len(img_list)):\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaa0a2265eb45f69f1c2e718776f3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=701), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm_notebook(img_list):\n",
    "#     if 'T190619_V1_K1/frame15748.jpg' not in img:\n",
    "#         continue\n",
    "    # inference on single image\n",
    "    results.append(inference_detector(model, img))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[i for i,r in enumerate(results) if len(r[0]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "N = 0 # nth image to be shown\n",
    "threshold = 0.10\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import colorsys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,12) # w, h\n",
    "\n",
    "# img = image.imread('../data/external/visdrone/train/sequences/uav0000243_00001_v/0000690.jpg').asnumpy()\n",
    "\n",
    "_GRAY = (218, 227, 218)\n",
    "_GREEN = (18, 127, 15)\n",
    "_WHITE = (255, 255, 255)\n",
    "font_scale=0.85\n",
    "\n",
    "im = cv2.imread(img_list[N])\n",
    "\n",
    "\n",
    "for i in filter(lambda x: x[-1] >= threshold, results[N][0]):\n",
    "    cv2.rectangle(im, (int(i[0]), int(i[1])),\n",
    "                     (int(i[2]), int(i[3])), _GREEN, 2)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    ((txt_w, txt_h), _) = cv2.getTextSize('person', font, font_scale, 1)\n",
    "    back_tl = int(i[0]), int(i[1] - 1.3 * txt_h)\n",
    "    back_br = int(i[0] + txt_w), int(i[1])\n",
    "    cv2.rectangle(im, back_tl, back_br, _GRAY, -1)\n",
    "    \n",
    "    cv2.rectangle(im, back_tl, back_br, _GRAY, -1)\n",
    "\n",
    "\n",
    "\n",
    "    txt_tl = int(i[0]), int(i[1]) - int(0.3 * txt_h)\n",
    "\n",
    "    cv2.putText(im, 'person: '+ str(i[4]) , txt_tl,\n",
    "                             cv2.FONT_HERSHEY_DUPLEX, font_scale, _WHITE, 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "im2 = im[:,:,::-1]\n",
    "plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread(img_list[N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# PREDS.TXT\n",
    "thres = [0.1]\n",
    "with open(prediction_file_path, 'w+') as f:\n",
    "    for img_path, img_preds in zip(img_list, results):\n",
    "        line = '/'.join(img_path.split('/')[-2:])\n",
    "        for i, preds in enumerate(img_preds[:2]):\n",
    "            for bbox in filter(lambda x: x[-1] >= thres[i], preds):\n",
    "                line += \",{},{},{},{},{}\".format(*bbox[:-1], i)\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUND TRUTH\n",
    "with open(ground_truth_file_path, 'w+') as f:\n",
    "    for img in anns:\n",
    "        line = '/'.join(img['filename'].split('/')[-2:])\n",
    "        for i, bbox in enumerate(img['ann']['bboxes']):\n",
    "            line += \",{},{},{},{},{}\".format(*bbox, img['ann']['labels'][i] - 1)\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /home/deep/miniconda3/envs/open-mmlab/bin/python ../eval/evaluate.py ground-truth.txt preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /home/deep/miniconda3/envs/open-mmlab/bin/python ../eval/t3_evaluate.py ground-truth.txt preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3.7 MMDetect",
   "language": "python",
   "name": "mmdetect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
