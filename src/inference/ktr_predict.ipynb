{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pickle\n",
    "from mmdetection.mmdet.apis import init_detector, inference_detector, show_result\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "prediction_file_path = 'preds.txt'\n",
    "ground_truth_file_path = 'ground-truth.txt'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone/epoch_1.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_mix/epoch_4.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone_pretrained/epoch_14.pth'\n",
    "\n",
    "config_file = '../../src/configs/libra_rcnn/libra_retinanet_r50_fpn_1x.py'\n",
    "checkpoint_file = '../mmdetection/work_dirs/libra_retinanet_r50_fpn_1x/epoch_2.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/retinanet_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/retinanet_r50_fpn_1x_visdrone/epoch_2.pth'\n",
    "\n",
    "# config_file = '../../src/configs/cascade_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../../models/work_dirs/cascade_rcnn_r50_fpn_1x-all/latest.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r101_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r101_fpn_1x/epoch_15.pth'\n",
    "\n",
    "# config_file = '../../models/google-cloud-models/cascade-t3-vis/config.py'\n",
    "# checkpoint_file = '../../models/google-cloud-models/cascade-t3-vis/epoch_1.pth'\n",
    "\n",
    "# img_list = ['../../data/t3-data/' + ann['filename'] for ann in anns]\n",
    "# img_list = ['../../data/' + ann['filename'] for ann in anns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0ea87576274c29bc98957e5e08e611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "img_list = ['../../data/ktr-test/test/B23072019_V1_K1/frame2885.jpg']\n",
    "\n",
    "for img in tqdm_notebook(img_list):\n",
    "#     if 'T190619_V1_K1/frame15748.jpg' not in img:\n",
    "#         continue\n",
    "    # inference on single image\n",
    "    results.append(inference_detector(model, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2l\n",
    "from mxnet import image\n",
    "\n",
    "d2l.set_figsize((20, 9))\n",
    "# img = image.imread('../data/external/visdrone/train/sequences/uav0000243_00001_v/0000690.jpg').asnumpy()\n",
    "img = image.imread(img_list[0]).asnumpy()\n",
    "\n",
    "# Save to the d2l package.\n",
    "def bbox_to_rect(bbox, color):\n",
    "    \"\"\"Convert bounding box to matplotlib format.\"\"\"\n",
    "    # Convert the bounding box (top-left x, top-left y, bottom-right x,\n",
    "    # bottom-right y) format to matplotlib format: ((upper-left x,\n",
    "    # upper-left y), width, height)\n",
    "    return d2l.plt.Rectangle(\n",
    "        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\n",
    "        fill=False, edgecolor=color, linewidth=2)\n",
    "\n",
    "fig = d2l.plt.imshow(img)\n",
    "\n",
    "for bbox in filter(lambda x: x[-1] >= 0.6, results[0][1]):\n",
    "    fig.axes.add_patch(bbox_to_rect(bbox[:-1], 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# {\n",
    "#  \"frame_id\": 568,\n",
    "#  \"objeler\": [\n",
    "#  {\n",
    "#  \"tur\": \"yaya\",\n",
    "#  \"x1\": 235,\n",
    "#  \"y1\": 26,\n",
    "#  \"x2\": 312,\n",
    "#  \"y2\": 98\n",
    "#  },\n",
    "#  {\n",
    "#  \"tur\": \"arac\",\n",
    "#  \"x1\": 533,\n",
    "#  \"y1\": 498,\n",
    "#  \"x2\": 603,\n",
    "#  \"y2\": 581\n",
    "#  }\n",
    "#  ]\n",
    "# }\n",
    "\n",
    "thres = [0.3, 0.7]\n",
    "results = []\n",
    "for img_path, img_preds in zip(img_list, results):\n",
    "    frame = img_path.split('/')[-1].split('.')[0][5:]\n",
    "    objects =[]\n",
    "    for i, preds in enumerate(img_preds[:2]):\n",
    "        for bbox in filter(lambda x: x[-1] >= thres[i], preds):\n",
    "            objects.append({\n",
    "                'tur': 'yaya' if i == 0 else 'arac',\n",
    "                'x1': int(bbox[0]),\n",
    "                'y1': int(bbox[1]),\n",
    "                'x2': int(bbox[2]),\n",
    "                'y2': int(bbox[3])\n",
    "            })\n",
    "            \n",
    "    results.append({\n",
    "        'frame_id': int(frame),\n",
    "        'objeler': objects\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3.7 MMDetect",
   "language": "python",
   "name": "mmdetect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
