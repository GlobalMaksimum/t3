{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from mmdetection.mmdet.apis import init_detector, inference_detector, show_result\n",
    "from tqdm import tqdm_notebook\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "prediction_file_path = 'preds.txt'\n",
    "ground_truth_file_path = 'ground-truth.txt'\n",
    "anns = pickle.load(open('../../data/t3-data-grid/test.pkl', 'rb'))\n",
    "tile_json = json.load(open('../../data/t3-data-grid/test_tiles.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = {}\n",
    "\n",
    "for i in tile_json.keys():\n",
    "    frame = i.split('-')[0]\n",
    "    if frame in frames_dict:\n",
    "        frames_dict[frame].append(i)\n",
    "    else:\n",
    "        frames_dict[frame] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone/epoch_1.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_mix/epoch_4.pth'\n",
    "\n",
    "# config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/old_workdir/faster_rcnn_r50_fpn_1x_visdrone_pretrained/epoch_14.pth'\n",
    "\n",
    "# config_file = '../../src/configs/libra_rcnn/libra_retinanet_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/libra_retinanet_r50_fpn_1x/epoch_2.pth'\n",
    "\n",
    "# config_file = '../configs/guided_anchoring/ga_retinanet_x101_32x4d_fpn_1x.py'\n",
    "# checkpoint_file = '../../models/work_dirs/ga_retinanet_x101_32x4d_fpn_1x/latest.pth'\n",
    "\n",
    "\n",
    "# config_file = '../mmdetection/configs/retinanet_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../mmdetection/work_dirs/retinanet_r50_fpn_1x_visdrone/epoch_2.pth'\n",
    "\n",
    "# config_file = '../../src/configs/cascade_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../../models/work_dirs/cascade_rcnn_r50_fpn_1x-all/latest.pth'\n",
    "\n",
    "\n",
    "# config_file = '../../models/google-cloud-models/cascade-t3-vis/config.py'\n",
    "# checkpoint_file = '../../models/google-cloud-models/cascade-t3-vis/epoch_1.pth'\n",
    "\n",
    "# config_file = '../../src/configs/cascade_rcnn_r50_fpn_1x.py'\n",
    "# checkpoint_file = '../../models/work_dirs/cascade_rcnn_r50_fpn_1x-cropped-t3only-nobp-yaya/latest.pth'\n",
    "\n",
    "config_file = '../mmdetection/configs/faster_rcnn_r50_fpn_1x.py'\n",
    "checkpoint_file = '../../models/work_dirs/faster_rcnn_r50_fpn_grid-yaya-t3-subset-visdrone/epoch_29.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "img_list = ['../../data/t3-data-grid/' + ann['filename'] for ann in anns]\n",
    "\n",
    "for img in tqdm_notebook(img_list):\n",
    "    results['/'.join(img.split('/')[-2:])[:-4]] = inference_detector(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_bboxes = {}\n",
    "for k, v in tqdm_notebook(frames_dict.items()):\n",
    "    frame_bboxes[k] = []\n",
    "    for vv in v:\n",
    "        bboxes = results[vv][0]\n",
    "        x, y, _, _ = tile_json[vv]\n",
    "        for bbox in bboxes:\n",
    "            frame_bboxes[k].append(bbox + [x, y, x, y, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_bboxes['T190619_V5_K1/frame6032']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, probs=None, overlapThresh=0.6):\n",
    "    \n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # bottom-left y-coordinate)\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = y2\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "    if probs is not None:\n",
    "        idxs = probs\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked\n",
    "    return np.concatenate((boxes[pick].astype(\"int\"), np.expand_dims(probs[pick], -1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_frame_bboxes = {}\n",
    "for frame, bboxes in frame_bboxes.items():\n",
    "    if len(bboxes) > 0:\n",
    "        boxes, probs = np.array(bboxes)[:,:4], np.array(bboxes)[:,-1]\n",
    "        nms_frame_bboxes[frame] = non_max_suppression_fast(boxes, probs)\n",
    "    else:\n",
    "        nms_frame_bboxes[frame] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# PREDS.TXT\n",
    "thres = [0.1]\n",
    "with open(prediction_file_path, 'w+') as f:\n",
    "    for img_path, img_preds in frame_bboxes.items():\n",
    "        line = '/'.join(img_path.split('/')[-2:]) + '.jpg'\n",
    "        for bbox in filter(lambda x: x[-1] >= thres[0], img_preds):\n",
    "            line += \",{},{},{},{},{}\".format(*bbox[:-1], 0)\n",
    "        f.write(line)\n",
    "        f.write('\\n')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDS.TXT over NMS PREDICTIONS\n",
    "thres = [0.2]\n",
    "with open(prediction_file_path, 'w+') as f:\n",
    "    for img_path, img_preds in nms_frame_bboxes.items():\n",
    "        line = '/'.join(img_path.split('/')[-2:]) + '.jpg'\n",
    "        for bbox in filter(lambda x: x[-1] >= thres[0], img_preds):\n",
    "            line += \",{},{},{},{},{}\".format(*bbox[:-1], 0)\n",
    "        f.write(line)\n",
    "        f.write('\\n')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = pickle.load(open('../../data/t3-data/only_yaya_test_frames.pkl', 'rb'))\n",
    "# GROUND TRUTH\n",
    "with open(ground_truth_file_path, 'w+') as f:\n",
    "    for img in anns:\n",
    "        line = '/'.join(img['filename'].split('/')[-2:])\n",
    "        for i, bbox in enumerate(img['ann']['bboxes']):\n",
    "            line += \",{},{},{},{},{}\".format(*bbox, img['ann']['labels'][i] - 1)\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /home/deep/miniconda3/envs/open-mmlab/bin/python ../eval/evaluate.py ground-truth.txt preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /home/deep/miniconda3/envs/open-mmlab/bin/python ../eval/t3_evaluate.py ground-truth.txt preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frame_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nms_frame_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nms_bboxes['T190619_V5_K1/frame6004.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "frame_and_boxes = nms_frame_bboxes\n",
    "\n",
    "\n",
    "# Input image base folder \n",
    "image_folder_base = '/home/deep/t3/data/t3-data/t3/'\n",
    "# Output video base folder\n",
    "video_output_base = './'\n",
    "\n",
    "\n",
    "video_name = '{}{}.mp4'.format(video_output_base, 'faster_rcnn_test')\n",
    "# sort images by frame\n",
    "\n",
    "results = []\n",
    "\n",
    "# get h,w to initialize canvas frame\n",
    "frame = cv2.imread(os.path.join(image_folder_base, 'T190619_V5_K1/frame6004.jpg'))\n",
    "\n",
    "# resize\n",
    "height, width, layers = frame.shape\n",
    "height //= 2 \n",
    "width //= 2\n",
    "# arguments: output_name, codec, fps, size\n",
    "video = cv2.VideoWriter(video_name, 0x7634706d, 5, (width,height)) \n",
    "\n",
    "for frame_path in tqdm(frame_and_boxes.keys(), total=len(frame_and_boxes)):\n",
    "\n",
    "\n",
    "    img_frame = cv2.imread(os.path.join(image_folder_base, frame_path + '.jpg'))\n",
    "\n",
    "    bboxes = frame_and_boxes[frame_path][:,:-1]\n",
    "    probs = frame_and_boxes[frame_path][:,-1]\n",
    "    for bbox, prob in zip(bboxes, probs):\n",
    "        if prob > 0.95:\n",
    "            mins = int(bbox[0]), int(bbox[1])\n",
    "            maxs = int(bbox[2]), int(bbox[3])\n",
    "            img_frame = cv2.rectangle(img_frame, mins, maxs,(0, 0, 250),2)            \n",
    "            txt = str(prob)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            ((txt_w, txt_h), _) = cv2.getTextSize(txt, font, 0.35, 1)\n",
    "            # Place text background.\n",
    "            back_tl = bbox[0], bbox[1] - int(1.3 * txt_h)\n",
    "            back_br = bbox[0] + txt_w, bbox[1]\n",
    "            # Show text.\n",
    "            txt_tl = int(bbox[0]), int(bbox[1] - int(0.3 * txt_h))\n",
    "            cv2.putText(img_frame, f'{prob:.3f}', txt_tl, font, 0.6, (218, 227, 218), lineType=cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    bottomLeftCornerOfText = (10,500)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (218, 227, 218)\n",
    "    lineType               = 2\n",
    "\n",
    "    cv2.putText(img_frame,str(frame_path),\n",
    "        bottomLeftCornerOfText, \n",
    "        font,\n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        lineType)\n",
    "    \n",
    "#     plt.rcParams[\"figure.figsize\"] = (20,14)\n",
    "#     plt.imshow(img_frame)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "    video.write(cv2.resize(img_frame, (width, height)))\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_and_boxes['T190619_V5_K1/frame6004'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(frame_bboxes, open('faster_rcnn_test_preds', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_bboxes = pickle.load(open('faster_rcnn_test_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['T190619_V5_K1/frame6004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3.7 MMDetect",
   "language": "python",
   "name": "mmdetect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
