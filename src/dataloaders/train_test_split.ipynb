{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# CONSTANTS\n",
    "SCENE_NAMES = ['T190619_V1_K1', 'T190619_V2_K1', 'T190619_V3_K1', 'B160519_V1_K1']\n",
    "SCENE_NAMES += ['T190619_V5_K1', 'B270619_V1_K1']\n",
    "NUM_THROW_AWAY = 90 # how many frames will be removed between each split\n",
    "TEST_SIZE, VAL_SIZE, TRAIN_SIZE = 0.4, 0.2, 0.4 # manually adjusted sample sizes\n",
    "\n",
    "DATA_PATH = '../../data/t3-data/merged_veriler/'\n",
    "FRAME_FILE_PATH = DATA_PATH + 'veriler.json'\n",
    "TRAINING_ANNOT_PATH = DATA_PATH + 'training.pkl'\n",
    "VAL_ANNOT_PATH = DATA_PATH + 'validation.pkl'\n",
    "TEST_ANNOT_PATH = DATA_PATH + 'test.pkl'\n",
    "\n",
    "\n",
    "# annotation files to be filled in\n",
    "train_annot, val_annot, test_annot = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t3_to_mmdetection_annotation(frame_annot):\n",
    "    \"\"\"\n",
    "    Transforms single t3 object annotation to mmdetection custom dataset annotation type.\n",
    "    Note that if class is `yaya`, it is represented with `0`. `Arac` is represented with `1`.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    T3 Annotation Type:\n",
    "    ------------------------------------------\n",
    "    {'frame_url': 'T190619_V1_K1/frame4948.jpg',\n",
    "     'frame_width': 1920,\n",
    "     'frame_height': 900,\n",
    "     'objeler': [{'tur': 'arac',\n",
    "       'x0': 61.2,\n",
    "       'y0': 417.1,\n",
    "       'x1': 121.7055,\n",
    "       'y1': 448.43},\n",
    "      {'tur': 'arac',\n",
    "       'x0': 1478.74,\n",
    "       'y0': 359.07,\n",
    "       'x1': 1544.8600000000001,\n",
    "       'y1': 387.74},\n",
    "      {'tur': 'arac', 'x0': 830.2, 'y0': 369.95, 'x1': 889.08, 'y1': 395.95}]}\n",
    "\n",
    "\n",
    "    MMDetection Annotation Type\n",
    "    -------------------------------------------\n",
    "    {'filename': 'T190619_V1_K1/frame4948.jpg',\n",
    "     'width': 1920,\n",
    "     'height': 900,\n",
    "     'ann': {'bboxes': array([[  61.2   ,  417.1   ,  121.7055,  448.43  ],\n",
    "             [1478.74  ,  359.07  , 1544.86  ,  387.74  ],\n",
    "             [ 830.2   ,  369.95  ,  889.08  ,  395.95  ]], dtype=float32),\n",
    "      'labels': array([1, 1, 1]),\n",
    "      'bboxes_ignore': [],\n",
    "      'labels_ignore': []}}\n",
    "    \n",
    "    \"\"\"\n",
    "    mmdetection_annot = {}\n",
    "    mmdetection_annot['filename'] = frame_annot['frame_url']\n",
    "    mmdetection_annot['width'] = frame_annot['frame_width']\n",
    "    mmdetection_annot['height'] = frame_annot['frame_height']\n",
    "    mmdetection_annot['ann'] = {'bboxes': [], 'labels': [], 'bboxes_ignore': [], 'labels_ignore': [] }\n",
    "    \n",
    "    for obj in frame_annot['objeler']:\n",
    "        bbox = [obj['x0'], obj['y0'], obj['x1'], obj['y1']]\n",
    "        # 1 if class is yaya, 2 if arac\n",
    "        if 'tur' in obj: # some objects' class are not labeled, we skip them\n",
    "            mmdetection_annot['ann']['bboxes'].append(bbox)\n",
    "            mmdetection_annot['ann']['labels'].append(1 if obj['tur'] != 'arac' else 2)\n",
    "            \n",
    "    # Type checks\n",
    "    mmdetection_annot['ann']['bboxes'] = np.array(mmdetection_annot['ann']['bboxes']).astype('float32')\n",
    "    mmdetection_annot['ann']['labels'] = np.array(mmdetection_annot['ann']['labels']).astype('int64')\n",
    "\n",
    "    return mmdetection_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for scene_name in SCENE_NAMES:\n",
    "        image_folder = DATA_PATH + '{}/'.format(scene_name)\n",
    "\n",
    "        # get names \n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n",
    "        # sort images by frame\n",
    "        images = sorted(images, key=lambda x: int(x.split('.')[0][5:]))\n",
    "\n",
    "        ### IDEA OF SPLITTING  ###\n",
    "        # Split frames as:\n",
    "        #\n",
    "        # Validation(val_ratio * len) - Throw away-Train(train_ratio * len) - Throw away - Test(test_ratio * len)\n",
    "        # \n",
    "        # Why throw away?: If we have n'th frame in validation and (n+1)'th frame in training this may cause overfitting.\n",
    "        ##########################\n",
    "\n",
    "\n",
    "        LEN_AFTER_TRASH = len(images) - 2 * NUM_THROW_AWAY\n",
    "\n",
    "        num_val, num_train, num_test = math.floor(LEN_AFTER_TRASH * VAL_SIZE),\\\n",
    "                                       math.floor(LEN_AFTER_TRASH * TRAIN_SIZE), math.floor(LEN_AFTER_TRASH * TEST_SIZE) \n",
    "\n",
    "        val_upper = num_val \n",
    "        train_lower = val_upper + NUM_THROW_AWAY\n",
    "        train_upper = train_lower + num_train\n",
    "        test_lower = train_upper + NUM_THROW_AWAY\n",
    "\n",
    "        val, train, test = images[:val_upper], images[train_lower:train_upper], images[test_lower:]\n",
    "\n",
    "        val = [os.path.join(scene_name, i) for i in val]\n",
    "        train = [os.path.join(scene_name, i) for i in train]\n",
    "        test = [os.path.join(scene_name, i) for i in test]\n",
    "\n",
    "        \n",
    "        # Sanity checks to prevent leakage\n",
    "        assert not len(set(val).intersection(set(train))), 'Same instance cannot be in both training and val set'\n",
    "        assert not len(set(test).intersection(set(train))), 'Same instance cannot be in both training and test set'\n",
    "\n",
    "        frames = json.load(open(FRAME_FILE_PATH))['frameler']\n",
    "        # fill the frames with objects to dictionaries\n",
    "        visited_frame_urls = []\n",
    "        for frame in frames:\n",
    "            # avoids duplicate frame annotations\n",
    "            if frame['frame_url'] in val and frame['frame_url'] not in visited_frame_urls:\n",
    "                val_annot.append(t3_to_mmdetection_annotation(frame))\n",
    "            elif frame['frame_url'] in train and frame['frame_url'] not in visited_frame_urls:\n",
    "                train_annot.append(t3_to_mmdetection_annotation(frame))\n",
    "            elif frame['frame_url'] in test and frame['frame_url'] not in visited_frame_urls:\n",
    "                test_annot.append(t3_to_mmdetection_annotation(frame))\n",
    "            visited_frame_urls.append(frame['frame_url'])\n",
    "        \n",
    "        del visited_frame_urls\n",
    "    \n",
    "    \n",
    "    # We use pickle instead of JSON beacuse bounding box arrays are required \n",
    "    # to be numpy arrays which is not possible with JSON\n",
    "    # Output files to Pickle\n",
    "    with open(TRAINING_ANNOT_PATH, 'wb') as handle:\n",
    "        pickle.dump(train_annot, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(VAL_ANNOT_PATH, 'wb') as handle:\n",
    "        pickle.dump(val_annot, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(TEST_ANNOT_PATH, 'wb') as handle:\n",
    "        pickle.dump(test_annot, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.1.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow GPU)",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
